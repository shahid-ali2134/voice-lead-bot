<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>AI Voice Lead Agent – Demo</title>
  <style>
    body{margin:0;font-family:Inter,Arial,sans-serif;background:radial-gradient(circle at top,#1f1f1f,#0b0b0b);color:#eaeaea}
    .container{max-width:1200px;margin:0 auto;padding:28px 18px 40px}
    h1{font-size:46px;margin:0;letter-spacing:.4px;line-height:1.05;position:relative;left:-12px}
    .subtitle{color:#aaa;margin-top:8px;font-size:14px;max-width:740px;position:relative;left:-12px}
    .grid{display:grid;grid-template-columns:1fr 360px;gap:18px;align-items:start;margin-top:18px}
    .panel{background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.08);border-radius:16px;padding:18px}
    .controls{display:flex;flex-wrap:wrap;gap:12px;align-items:center}
    .status{font-size:12px;padding:6px 10px;border-radius:999px;background:#111;border:1px solid #333;color:#9be7ff}
    .good{color:#7CFC9A}.warn{color:#ffd18a}.bad{color:#ff9b9b}.muted{color:#bdbdbd}
    button{background:linear-gradient(135deg,#3b82f6,#2563eb);border:none;color:#fff;padding:12px 18px;border-radius:12px;font-size:14px;cursor:pointer;box-shadow:0 6px 18px rgba(0,0,0,.35)}
    button.secondary{background:#222;border:1px solid #333}
    button:disabled{opacity:.45;cursor:not-allowed}
    .hint{font-size:12px;color:#999;margin-top:8px}
    .equalHeight{height:520px;display:flex;flex-direction:column}
    .chat{flex:1;overflow-y:auto;display:flex;flex-direction:column;gap:12px;padding-right:6px}
    .bubble{max-width:78%;padding:12px 14px;border-radius:14px;font-size:14px;line-height:1.45;white-space:pre-wrap}
    .user{align-self:flex-end;background:linear-gradient(135deg,#2563eb,#1d4ed8)}
    .bot{align-self:flex-start;background:#151515;border:1px solid #2a2a2a}
    .leadHeader{margin-bottom:10px}
    h3{margin:0;font-size:16px;color:#cfcfcf;letter-spacing:.2px}
    .leadSub{color:#9a9a9a;font-size:12px;margin-top:4px}
    pre{background:#050505;border:1px solid #222;border-radius:12px;padding:14px;font-size:12px;color:#7CFC9A;overflow:auto;flex:1;margin:0}
    @media (max-width:980px){.grid{grid-template-columns:1fr}h1,.subtitle{left:0}.equalHeight{height:auto}}
  </style>
</head>
<body>
  <div class="container">
    <h1>AI Voice Lead Agent</h1>
    <div class="subtitle">Realtime lead qualification voice demo (Whisper + ElevenLabs + VAD).</div>

    <div class="grid">
      <div>
        <div class="panel" style="margin-bottom:18px;">
          <div class="controls">
            <span class="status" id="conn">Disconnected</span>
            <span class="status">State: <b id="state">–</b></span>
            <span class="status muted" id="micState">Mic: Not enabled</span>
            <span class="status muted" id="listenState">Listening: –</span>

            <button id="btnMic" class="secondary">Enable Microphone</button>
            <button id="btnConnect">Connect</button>
            <button id="btnReset" class="secondary" disabled>Reset</button>
          </div>
          <div class="hint" id="hint">1) Enable Microphone  2) Connect  3) Talk when it says “Speak now”.</div>
        </div>

        <div class="panel equalHeight">
          <div class="chat" id="chat"></div>
        </div>
      </div>

      <div class="panel equalHeight">
        <div class="leadHeader">
          <h3>Captured Lead</h3>
          <div class="leadSub">Updates when the lead becomes qualified</div>
        </div>
        <pre id="lead">{}</pre>
      </div>
    </div>
  </div>

<script>
  const WS_URL = "ws://localhost:8765";

  let ws = null;
  let stream = null;
  let micEnabled = false;

  // speaking + listening gate
  let agentSpeaking = false;
  let listening = false;

  // audio pipeline
  let audioCtx = null;
  let sourceNode = null;
  let processor = null;
  let sampleRateIn = 48000;

  // capture buffer
  let chunks = [];
  let speechStarted = false;
  let silenceMs = 0;

  // tuning
  const TARGET_SR = 16000;
  const FRAME_MS = 30;           // match backend expectation
  const START_RMS = 0.012;       // start speaking threshold
  const STOP_RMS  = 0.010;       // silence threshold
  const STOP_AFTER_MS = 700;     // stop after this much silence
  const MIN_SPEECH_MS = 280;     // ignore too-short blips

  const connEl = document.getElementById("conn");
  const stateEl = document.getElementById("state");
  const chatEl = document.getElementById("chat");
  const leadEl = document.getElementById("lead");
  const micStateEl = document.getElementById("micState");
  const listenStateEl = document.getElementById("listenState");
  const hintEl = document.getElementById("hint");

  const btnMic = document.getElementById("btnMic");
  const btnConnect = document.getElementById("btnConnect");
  const btnReset = document.getElementById("btnReset");

  function addBubble(role, text) {
    const div = document.createElement("div");
    div.className = "bubble " + (role === "user" ? "user" : "bot");
    div.textContent = text;
    chatEl.appendChild(div);
    chatEl.scrollTop = chatEl.scrollHeight;
  }

  function setMicState(text, mode="muted") {
    micStateEl.textContent = "Mic: " + text;
    micStateEl.className = "status " + mode;
  }

  function setListenState(text, mode="muted") {
    listenStateEl.textContent = "Listening: " + text;
    listenStateEl.className = "status " + mode;
  }

  function playTTSAudio(b64) {
    agentSpeaking = true;
    stopListening();

    const binary = atob(b64);
    const bytes = new Uint8Array(binary.length);
    for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);

    const blob = new Blob([bytes], { type: "audio/wav" });
    const url = URL.createObjectURL(blob);
    const audio = new Audio(url);

    audio.play().catch(() => {});
    audio.onended = () => {
      URL.revokeObjectURL(url);
      agentSpeaking = false;

      // ✅ auto-open mic after agent finishes
      startListening();
    };
  }

  async function enableMic() {
    try {
      stream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true }
      });

      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      sampleRateIn = audioCtx.sampleRate;

      sourceNode = audioCtx.createMediaStreamSource(stream);
      processor = audioCtx.createScriptProcessor(4096, 1, 1);

      sourceNode.connect(processor);
      processor.connect(audioCtx.destination);

      processor.onaudioprocess = (e) => {
        if (!listening) return;

        const input = e.inputBuffer.getChannelData(0);
        const rms = computeRMS(input);

        // start gate
        if (!speechStarted) {
          if (rms >= START_RMS) {
            speechStarted = true;
            silenceMs = 0;
            chunks = [];
            setListenState("Speak now…", "good");
          } else {
            setListenState("Waiting…", "muted");
            return;
          }
        }

        // once started, keep buffering
        chunks.push(new Float32Array(input));

        // stop gate
        if (rms < STOP_RMS) silenceMs += (input.length / sampleRateIn) * 1000;
        else silenceMs = 0;

        if (silenceMs >= STOP_AFTER_MS) {
          // stop and send
          stopListening(true);
        }
      };

      micEnabled = true;
      setMicState("Enabled", "good");
      setListenState("Ready", "muted");
      hintEl.textContent = "Microphone enabled. Click Connect.";
    } catch (e) {
      micEnabled = false;
      setMicState("Permission denied", "bad");
      hintEl.textContent = "Mic permission denied. Please allow microphone access in the browser.";
    }
  }

  function computeRMS(arr) {
    let s = 0;
    for (let i = 0; i < arr.length; i++) s += arr[i] * arr[i];
    return Math.sqrt(s / arr.length);
  }

  function startListening() {
    if (!micEnabled) return;
    if (!ws || ws.readyState !== 1) return;
    if (agentSpeaking) return;

    listening = true;
    speechStarted = false;
    silenceMs = 0;
    chunks = [];
    setListenState("Waiting…", "muted");
    hintEl.textContent = "Speak naturally. It will stop automatically when you finish.";
  }

  async function stopListening(sendIfAny=false) {
    if (!listening) return;
    listening = false;

    if (!sendIfAny) {
      setListenState("Paused", "warn");
      return;
    }

    // must have enough buffered audio
    const wavB64 = buildWavB64FromChunks();
    if (!wavB64) {
      setListenState("No speech", "warn");
      return;
    }

    setListenState("Sending…", "warn");
    ws.send(JSON.stringify({ type: "audio", b64: wavB64 }));
    setListenState("Sent", "good");
  }

  function buildWavB64FromChunks() {
    if (chunks.length === 0) return null;

    // merge
    let total = 0;
    for (const c of chunks) total += c.length;
    const merged = new Float32Array(total);
    let pos = 0;
    for (const c of chunks) { merged.set(c, pos); pos += c.length; }

    // minimum speech duration
    const durMs = (merged.length / sampleRateIn) * 1000;
    if (durMs < MIN_SPEECH_MS) return null;

    // downsample to 16k
    const down = downsample(merged, sampleRateIn, TARGET_SR);
    const pcm16 = floatTo16BitPCM(down);
    const wavBytes = encodeWAV(pcm16, TARGET_SR);

    // base64
    let bin = "";
    for (let i = 0; i < wavBytes.length; i++) bin += String.fromCharCode(wavBytes[i]);
    return btoa(bin);
  }

  function downsample(buffer, inRate, outRate) {
    if (outRate === inRate) return buffer;
    const ratio = inRate / outRate;
    const newLen = Math.floor(buffer.length / ratio);
    const out = new Float32Array(newLen);
    let offset = 0;

    for (let i = 0; i < newLen; i++) {
      const start = Math.floor(i * ratio);
      const end = Math.floor((i + 1) * ratio);
      let sum = 0;
      let count = 0;
      for (let j = start; j < end && j < buffer.length; j++) { sum += buffer[j]; count++; }
      out[offset++] = count ? (sum / count) : 0;
    }
    return out;
  }

  function floatTo16BitPCM(float32) {
    const out = new Int16Array(float32.length);
    for (let i = 0; i < float32.length; i++) {
      let s = Math.max(-1, Math.min(1, float32[i]));
      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return out;
  }

  function encodeWAV(pcm16, sr) {
    const buffer = new ArrayBuffer(44 + pcm16.length * 2);
    const view = new DataView(buffer);

    function writeString(offset, str) {
      for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));
    }

    writeString(0, "RIFF");
    view.setUint32(4, 36 + pcm16.length * 2, true);
    writeString(8, "WAVE");
    writeString(12, "fmt ");
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);          // mono
    view.setUint32(24, sr, true);
    view.setUint32(28, sr * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, "data");
    view.setUint32(40, pcm16.length * 2, true);

    let offset = 44;
    for (let i = 0; i < pcm16.length; i++, offset += 2) view.setInt16(offset, pcm16[i], true);
    return new Uint8Array(buffer);
  }

  btnMic.onclick = enableMic;

  btnConnect.onclick = () => {
    if (!micEnabled) {
      hintEl.textContent = "Enable microphone first.";
      setMicState("Not enabled", "bad");
      return;
    }

    ws = new WebSocket(WS_URL);

    ws.onopen = () => {
      connEl.textContent = "Connected";
      connEl.className = "status good";
      btnReset.disabled = false;
      hintEl.textContent = "Connected. The mic will open automatically after the agent finishes speaking.";
    };

    ws.onclose = () => {
      connEl.textContent = "Disconnected";
      connEl.className = "status";
      btnReset.disabled = true;
      stopListening(false);
      setListenState("–", "muted");
    };

    ws.onmessage = (ev) => {
      const msg = JSON.parse(ev.data);

      if (msg.type === "state") stateEl.textContent = msg.value;
      else if (msg.type === "user_text") addBubble("user", msg.text || "");
      else if (msg.type === "agent_text") addBubble("bot", msg.text || "");
      else if (msg.type === "tts_audio") playTTSAudio(msg.b64);
      else if (msg.type === "lead") leadEl.textContent = JSON.stringify(msg.data || {}, null, 2);
      else if (msg.type === "agent_speaking") {
        agentSpeaking = !!msg.value;
        if (agentSpeaking) stopListening(false);
        else startListening();
      }
      else if (msg.type === "vad") {
        if (msg.value === "no_speech") setListenState("No speech (ignored)", "warn");
        if (msg.value === "empty_transcript") setListenState("Empty transcript", "warn");
      }
      else if (msg.type === "error") addBubble("bot", "ERROR: " + (msg.message || "Unknown error"));
    };
  };

  btnReset.onclick = () => {
    if (!ws || ws.readyState !== 1) return;
    chatEl.innerHTML = "";
    leadEl.textContent = "{}";
    ws.send(JSON.stringify({ type: "reset" }));
  };
</script>
</body>
</html>
